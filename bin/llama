#!/usr/bin/env python

import json
import os
import sys
import urllib.request

# these models hallucinate
# model = "llama3.1-8b-instant"
# model = "llama-3.1-70b-versatile"

url = "https://api.groq.com/openai/v1/chat/completions"
model = "llama3-8b-8192"
big =  "llama3-70b-8192"

def read_token(name):
	with open(name) as f:
		return f.read().strip()

tpath = os.path.join(os.getenv("HOME"), ".config/groq/token")
token = read_token(tpath)

if len(sys.argv) > 1 and sys.argv[1] == "-b":
	model = big
prompt = sys.stdin.read()
message = {"messages": [{"role": "user","content": prompt}], "model": model}

req = urllib.request.Request(url, json.dumps(message).encode())
req.add_header("Content-Type", "application/json")
req.add_header("Authorization", "Bearer "+token)
# groq blocks urllib's user agent?!
req.add_header("User-Agent", "curl/8.9.0")

with urllib.request.urlopen(req) as resp:
	reply = json.load(resp)
	print(reply["choices"][0]["message"]["content"])
