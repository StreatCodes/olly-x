#!/usr/bin/env python

import json
import os
import sys
import urllib.request

url = "https://api.groq.com/openai/v1/chat/completions"
# small models include:
# llama-3.1-8b-instant
# llama-3.2-3b-preview
# llama-3.2-1b-preview
model = "llama-3.1-8b-instant"
big = "llama-3.3-70b-versatile"

def read_token(name):
	with open(name) as f:
		return f.read().strip()

tpath = os.path.join(os.getenv("HOME"), ".config/groq/token")
token = read_token(tpath)

if len(sys.argv) > 1 and sys.argv[1] == "-b":
	model = big
prompt = sys.stdin.read()
message = {"messages": [{"role": "user","content": prompt}], "model": model}

req = urllib.request.Request(url, json.dumps(message).encode())
req.add_header("Content-Type", "application/json")
req.add_header("Authorization", "Bearer "+token)
# groq blocks urllib's user agent
req.add_header("User-Agent", "curl/8.9.0")

with urllib.request.urlopen(req) as resp:
	reply = json.load(resp)
	print(reply["choices"][0]["message"]["content"])
